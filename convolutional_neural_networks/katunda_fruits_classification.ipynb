{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "katunda_fruits_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Katunda Fruits Classification\n",
        "---\n",
        "In this notebook, we train a **CNN** to classify images from the Katunda-classification dataset.\n",
        "\n",
        "The images in this dataset are fruit images images of passion fruits that fall into one of three(3) classes; \n",
        "* Brown Spot\n",
        "* Healthy\n",
        "* Woodiness\n",
        ".\n",
        "\n",
        "Code written by `Ochieng Tony Blair` and `Olwa Micheal Okaka` of [The Marconi Society Machine Learning Laboratory](https://marconilab.org/)\n",
        "\n"
      ],
      "metadata": {
        "id": "QuS9B_yNN1F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_10K2Mchb8l-",
        "outputId": "6a23e5f3-98cc-4451-c97e-a5f2cf508afa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/intern')"
      ],
      "metadata": {
        "id": "iHeF9TfCbylb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test for CUDA"
      ],
      "metadata": {
        "id": "eHsT-k-FQzxj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_NNq5biMkiO",
        "outputId": "5e461878-bb1f-47ab-abd5-0051d30d08c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available! Training on GPU ...\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "  print('CUDA is not available. Training on CPU ...')\n",
        "else:\n",
        "  print('CUDA is available! Training on GPU ...')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Load the Data\n",
        "\n",
        "We load in the training and test data, split the training data into a training and validation set, then create DataLoaders for each of these sets of data."
      ],
      "metadata": {
        "id": "3qpLuPKXSBXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 32\n",
        "# percentage of traing set to use as validation\n",
        "valid_size = 0.2\n",
        "\n",
        "#convert data to a normalized torch.FloatTensor\n",
        "train_transforms = transforms.Compose([transforms.Resize(224),\n",
        "                                       transforms.RandomRotation(20),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.5, 0.5,  0.5],\n",
        "                                                            [0.5, 0.5, 0.5])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(224),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomRotation(10),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.5, 0.5,  0.5],\n",
        "                                                           [0.5, 0.5, 0.5])])\n",
        "\n",
        "# choose the training and test datasets\n",
        "data_dir = '/content/drive/MyDrive/intern/introduction_to_pytorch/intro-to-pytorch/sample_fruits'\n",
        "\n",
        "# Pass transforms in here after loading dataset\n",
        "train_data = datasets.ImageFolder(data_dir + '/training', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/validation', transform=test_transforms)\n",
        "\n",
        "# Obtain training indices to be used for validation\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# prepare data loaders (combine dataset and sampler)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers )\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n",
        "\n",
        "#specify the classes\n",
        "classes = ['BrownSpot', 'Healthy', 'Woodiness']\n"
      ],
      "metadata": {
        "id": "QOQSFYWrR6k7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize a Batch of Training Data"
      ],
      "metadata": {
        "id": "-L7GwpE8ZQjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# helper fuction to un-normalize and disply an image\n",
        "def imshow(img):\n",
        "  img = img/2 + 0.5 #\n",
        "  plt.imshow(np.transpose(img, (1,2,0))) # convert from Tensor image"
      ],
      "metadata": {
        "id": "NoN3yqGwZPpR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain one batch from training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy() # convert images to numpy for display\n",
        "\n",
        "#plot the images in the batch with labels\n",
        "fig = plt.figure(figsize=(25, 25))\n",
        "#display 20 images\n",
        "for idx in np.arange(20):\n",
        "  ax = fig.add_subplot(4, 5, idx+1, xticks=[], yticks=[])\n",
        "  imshow(images[idx])\n",
        "  ax.set_title(classes[labels[idx]])"
      ],
      "metadata": {
        "id": "2P6uY_ctaGPC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View an Image in More Detail\n",
        "\n",
        "Here, we look at the normalized red, green, and blue (RGB) color channels as three separate, grayscale intensity images."
      ],
      "metadata": {
        "id": "VwAniBdoeVxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rgb_img = np.squeeze(images[3])\n",
        "# channels = ['red channel', 'green channel', 'blue channel']\n",
        "\n",
        "# fig = plt.figure(figsize = (36, 36)) \n",
        "# for idx in np.arange(rgb_img.shape[0]):\n",
        "#     ax = fig.add_subplot(1, 3, idx + 1)\n",
        "#     img = rgb_img[idx]\n",
        "#     ax.imshow(img, cmap='gray')\n",
        "#     ax.set_title(channels[idx])\n",
        "#     width, height = img.shape\n",
        "#     thresh = img.max()/2.5\n",
        "#     for x in range(width):\n",
        "#         for y in range(height):\n",
        "#             val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
        "#             ax.annotate(str(val), xy=(y,x),\n",
        "#                     horizontalalignment='center',\n",
        "#                     verticalalignment='center', size=8,\n",
        "#                     color='white' if img[x][y]<thresh else 'black')"
      ],
      "metadata": {
        "id": "YAIDO8z5cnXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Define the Network Architecture"
      ],
      "metadata": {
        "id": "uSEuwYYkfYEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # covolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3)\n",
        "        self.conv5 = nn.Conv2d(64, 64, 3)\n",
        "        self.conv6 = nn.Conv2d(64, 64, 3)\n",
        "        # max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(64, 64)\n",
        "        self.fc2 = nn.Linear(64, 3)\n",
        "        # dropout layer (p=0.25)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # add sequence of convolutional and max pooling layers\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = self.pool(F.relu(self.conv5(x)))\n",
        "        x = self.pool(F.relu(self.conv6(x)))\n",
        "        # flatten image input\n",
        "        x = x.view(-1, 64)\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add 1st hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        x = F.softmax(self.fc2(x), dim =1)\n",
        "        #print(x.shape)\n",
        "        return x\n",
        "\n",
        "# create a complete CNN\n",
        "model = Net()\n",
        "print(model)\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "if train_on_gpu:\n",
        "    model.cuda()"
      ],
      "metadata": {
        "id": "aPz5z5-Gf4C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specify Loss Function and Optimizer\n",
        "\n",
        "Decide on a loss and optimization function that is best suited for this classification task."
      ],
      "metadata": {
        "id": "F37USjkKhhda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# specify loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "R2BieZUUhgdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Train the Network\n"
      ],
      "metadata": {
        "id": "x5rZA9FfiEP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 100\n",
        "\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "train_losses, valid_losses = [], []\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        #print(output.shape)\n",
        "        #pass\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in valid_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        #print(output.shape)\n",
        "        #pass\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
        "\n",
        "    # At completion of epoch\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'katunda_fruit_model.pt')\n",
        "        valid_loss_min = valid_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hzpnKsgiMS-",
        "outputId": "389718de-af84-4105-f3cd-5659590d3116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 1.097283 \tValidation Loss: 1.085811\n",
            "Validation loss decreased (inf --> 1.085811).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 1.039785 \tValidation Loss: 1.052496\n",
            "Validation loss decreased (1.085811 --> 1.052496).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.976550 \tValidation Loss: 1.021878\n",
            "Validation loss decreased (1.052496 --> 1.021878).  Saving model ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting loss curves"
      ],
      "metadata": {
        "id": "YsE0pg390gs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "1b_AfFdb0M7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label='Training loss')\n",
        "plt.plot(valid_losses, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ],
      "metadata": {
        "id": "bYTGbzcm0Ti0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Load the Model with the Lowest Validation Loss"
      ],
      "metadata": {
        "id": "c6EdGXRPaXFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('katunda_fruit_model.pt'))"
      ],
      "metadata": {
        "id": "WwClBf4CYDE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Test the Trained Network\n"
      ],
      "metadata": {
        "id": "WmRIrgUyabZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# track test loss\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval()\n",
        "# iterate over test data\n",
        "for data, target in test_loader:\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    if train_on_gpu:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(batch_size):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "# average test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(3):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "metadata": {
        "id": "6TPgd_Iuai75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Sample Test Results"
      ],
      "metadata": {
        "id": "m3wmvMG1asB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain one batch of test images\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "images.numpy()\n",
        "\n",
        "# move model inputs to cuda, if GPU available\n",
        "if train_on_gpu:\n",
        "    images = images.cuda()\n",
        "\n",
        "# get sample outputs\n",
        "output = model(images)\n",
        "# convert output probabilities to predicted class\n",
        "_, preds_tensor = torch.max(output, 1)\n",
        "preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
        "\n",
        "# plot the images in the batch, along with predicted and true labels\n",
        "fig = plt.figure(figsize=(25, 25))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(4, 5, idx+1, xticks=[], yticks=[])\n",
        "    imshow(images[idx] if not train_on_gpu else images[idx].cpu())\n",
        "    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n",
        "                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))"
      ],
      "metadata": {
        "id": "s97HAZP3au6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}